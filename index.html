<!DOCTYPE HTML>
<html lang="en"><head>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Miguel Farinha</title>
  
  <meta name="author" content="Miguel Farinha">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <style type="text/css">
    /* fonts omitted for brevity — keep as is */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .fade {
      transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }

    .phone-teasers {
      display: none;
    }

    @media only screen and (max-width: 768px) {
      .abstract {
        display: none;
      }

      .comp-teasers {
        display: none;
      }

      .phone-teasers {
        display: block;
      }
    }

    /* --- Modal styles for image expansion --- */
    .modal {
      display: none;
      position: fixed;
      z-index: 1000;
      padding-top: 60px;
      left: 0;
      top: 0;
      width: 100%;
      height: 100%;
      overflow: auto;
      background-color: rgba(0,0,0,0.9);
    }

    .modal-content {
      margin: auto;
      display: block;
      max-width: 90%;
      max-height: 80vh;
      border-radius: 6px;
    }

    .close {
      position: absolute;
      top: 20px;
      right: 35px;
      color: #fff;
      font-size: 30px;
      font-weight: bold;
      cursor: pointer;
    }
  </style>

  <link rel="icon" class="top-icon" type="image/png" href="images/icon.png">

  <script>
    const icons = [
      "images/icons/sunglasses.png",
      "images/icons/computer.png",
      "images/icons/cowboy.png",
      "images/icons/smile.png"
    ];
    const randomIcon = icons[Math.floor(Math.random() * icons.length)];
    const iconElement = document.querySelector(".top-icon");
    iconElement.href = randomIcon;
  </script>

</head>

<body>
  <table style="width:100%;max-width:900px;border:0;margin:auto;"><tbody>
    <tr>
      <td>
        <table style="width:100%;border:0;margin:auto;"><tbody>
          <tr>
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Miguel Farinha</name>
              </p>
              <p>Hello! I am a CS PhD student at the University of Oxford working with <a target="_blank" href="https://ronnie-clark.co.uk/index.html">Professor Ronald Clark</a> on building <strong>foundation models for 3D understanding and perception</strong>.</p> 
              
              <p>I obtained my masters degree at the University of Lisbon studying Applied Mathematics with a focus on Probability and Statistics and my bachelors degree at the University of Lisbon studying Biomedical Engineering.</p>
              <p style="text-align:center">
                    [
                <a target="_blank" href="mailto:miguelffarinha@gmail.com">Email</a> &nbsp;/&nbsp;
                <a target="_blank" href="https://github.com/mlfarinha/">Github</a> &nbsp;/&nbsp;
                <a target="_blank" href="https://scholar.google.com/citations?user=HE6se3sAAAAJ&hl=pt-PT">Google Scholar</a> &nbsp;/&nbsp;
                <a target="_blank" href="https://www.linkedin.com/in/miguel-farinha-973a051b5/">LinkedIn</a> &nbsp;/&nbsp;
                <a target="_blank" href="images/cv.pdf">CV</a>
                    ]
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a target="_blank"><img style="width:100%;max-width:100%" alt="profile photo" src="images/miguel.jpeg"></a>
            </td>
          </tr>
        </tbody></table>

        <h2>Works in Progress</h2>
        <table style="width:100%;border:0;margin:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle" class="comp-teasers">
              <img src="images/sd3_recon.jpg" alt="hpp" style="border-style:none;width:350px">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Estimating Geometry and Pose for Scene Reconstruction</papertitle>
              <p class="summary">Unifying depth and camera motion estimation from RGB images to enable consistent 3D scene reconstruction.</p>
              
              <a href="javascript:void(0)" class="toggle-overview">[Overview]</a>
              <div class="abstract" style="display:none;">
                This project develops a framework that jointly estimates scene geometry (depth) 
                and camera motion directly from pairs of RGB images. We combine <strong>visual 
                foundation models</strong> (e.g., SD3.5, DINOv2) with <strong>geometric optimization</strong> 
                to refine predictions into a consistent 3D representation.  
                <br><br>
                Our approach performs gradient descent over a simple least-squares objective, 
                aligning predicted optical flow with correspondences from an off-the-shelf 
                flow estimator. By fine-tuning pretrained foundation models to predict 
                affine-invariant depth and optical flow jointly, we bridge geometry and motion 
                estimation in a single unified system.  
                <br><br>
                <strong>Contribution:</strong> A method that integrates learning-based priors with 
                optimization, enabling robust 3D scene reconstruction from multiple RGB views.
              </div>
              <div class="phone-teasers" style="display:flex;justify-content:center;margin-top:1em;">
                <img class="phone-teasers" src="images/sd3_recon.jpg" alt="hpp" style="border-style:none;width:300px">
              </div>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle" class="comp-teasers">
              <img src="images/svd_relighting.jpg" alt="hpp" style="border-style:none;width:350px">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Scene Understanding and Perception using Multi-view Diffusion Priors</papertitle>
              <p class="summary">Building complete 3D scene models, including geometry and material properties, from multi-view RGB images.</p>
              
              <a href="javascript:void(0)" class="toggle-overview">[Overview]</a>
              <div class="abstract" style="display:none;">
                This work aims to recover a full 3D representation of indoor scenes — geometry 
                (depth and normals) and appearance (SVBRDF) — directly from RGB images.  
                <br><br>
                We adapt the <strong>Stable Video Diffusion</strong> model to a multi-view setting, 
                conditioning it on several images of a scene and training it to output depth 
                maps, surface normals, and spatially varying reflectance properties. This 
                approach leverages <strong>diffusion priors</strong> for learning consistent multi-view 
                geometry and appearance estimation.  
                <br><br>
                <strong>Contribution:</strong> A novel diffusion-based method that jointly estimates 
                geometry and SVBRDFs, providing a complete 3D scene model. This enables 
                downstream applications such as relighting, novel view synthesis, and 3D 
                reconstruction.
              </div>
              <div class="phone-teasers" style="display:flex;justify-content:center;margin-top:1em;">
                <img class="phone-teasers" src="images/svd_relighting.jpg" alt="hpp" style="border-style:none;width:300px">
              </div>
            </td>
          </tr>

        </tbody></table>
        Template from <a target="_blank" href="https://jonbarron.info/">Jon Barron</a>.
      </td>
    </tr>
  </tbody></table>

  <!-- Modal for expanded images -->
  <div id="imgModal" class="modal">
    <span class="close">&times;</span>
    <img class="modal-content" id="modalImg">
  </div>

  <script>
    // Toggle overview text
    document.querySelectorAll('.toggle-overview').forEach(link => {
      link.addEventListener('click', () => {
        const abstract = link.nextElementSibling;
        if (abstract.style.display === "none") {
          abstract.style.display = "block";
          link.textContent = "[Hide Overview]";
        } else {
          abstract.style.display = "none";
          link.textContent = "[Overview]";
        }
      });
    });

    // Modal logic
    const modal = document.getElementById("imgModal");
    const modalImg = document.getElementById("modalImg");
    const closeBtn = document.querySelector(".close");

    document.querySelectorAll("td img").forEach(img => {
      img.style.cursor = "pointer";
      img.addEventListener("click", () => {
        modal.style.display = "block";
        modalImg.src = img.src;
      });
    });

    closeBtn.onclick = () => { modal.style.display = "none"; }
    modal.onclick = (event) => {
      if (event.target === modal) {
        modal.style.display = "none";
      }
    }
  </script>
  
</body>
</html>